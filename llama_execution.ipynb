{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e94003",
   "metadata": {},
   "source": [
    "# PROYECTO PROCESAMIENTO LENGUAJE NATURAL MINI-LLAMA\n",
    "Sebastián Insuasti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a9f36",
   "metadata": {},
   "source": [
    "En este notebook se ejecutará los códigos guía sugerios en el proyecto para revisar si la implementación del Mini Llama fue satisfactoria. Así también, se realiza gráficas de los resultados más destacables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293fffe",
   "metadata": {},
   "source": [
    "## Reference Commands and Expected Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3179bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_llama import get_args, generate_sentence, test_with_prompting, train, test, train_lora, seed_everything\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8b724",
   "metadata": {},
   "source": [
    "### Definición de Clase Args \n",
    "\n",
    "Se modifica la implementación original para que se pueda implementar de forma más amigable en \"notebook\" y no únicamente con los comandos predeterminados en el terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e615984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, option=\"generate\", epochs=5, lr=2e-5, seed=1337,\n",
    "                 train=\"data/cfimdb-train.txt\", dev=\"data/cfimdb-dev.txt\",\n",
    "                 test=\"data/cfimdb-test.txt\", label_names=\"data/cfimdb-label-mapping.json\",\n",
    "                 pretrained_model_path=\"stories42M.pt\", max_sentence_len=None,\n",
    "                 use_gpu=True, generated_sentence_low_temp_out=\"generated-sentence-temp-0.txt\",\n",
    "                 generated_sentence_high_temp_out=\"generated-sentence-temp-1.txt\",\n",
    "                 dev_out=\"cfimdb-dev-prompting-output.txt\", test_out=\"cfimdb-test-prompting-output.txt\",\n",
    "                 lora_rank=4, lora_alpha=1.0, batch_size=8, hidden_dropout_prob=0.3):\n",
    "        \n",
    "        self.option = option\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.seed = seed\n",
    "        self.train = train\n",
    "        self.dev = dev\n",
    "        self.test = test\n",
    "        self.label_names = label_names\n",
    "        self.pretrained_model_path = pretrained_model_path\n",
    "        self.max_sentence_len = max_sentence_len\n",
    "        self.use_gpu = use_gpu\n",
    "        self.generated_sentence_low_temp_out = generated_sentence_low_temp_out\n",
    "        self.generated_sentence_high_temp_out = generated_sentence_high_temp_out\n",
    "        self.dev_out = dev_out\n",
    "        self.test_out = test_out\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_alpha = lora_alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b5743",
   "metadata": {},
   "source": [
    "### Time\n",
    "\n",
    "Se declara una función de Tiempo para determinar el tiempo de ejecución de las funciones implementadas para hacer text generation, zero-shot, finetuning and lora finetuning. Se utiliza esta función como un decorador para envolver todas las funciones que se desea implementar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24571946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timed(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(f\"Tiempo: {func.__name__} ejecutada en {end - start:.4f} segundos\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "timed_generate_sentence = timed(generate_sentence)\n",
    "timed_test_with_prompting = timed(test_with_prompting)\n",
    "timed_train = timed(train)\n",
    "timed_train_lora = timed(train_lora)\n",
    "timed_test = timed(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159fa576",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b7223",
   "metadata": {},
   "source": [
    "**Comando Original**:\n",
    "python run_llama.py --option generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d10ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from stories42M.pt\n",
      "Temperature is 0.0\n",
      "Victor Frankenstein, a young scientist obsessed with uncovering the secrets of life, succeeds in animating a creature assembled from the unknown. Everyone in the village was curious to know what the creature was.\n",
      "One day, a young girl called Lily asked, \"What is unlocking?\"\n",
      "Lily smiled and said, \"I am unlocking the mystery of the unknown.\"\n",
      "Lily was excited to find out what the mystery was. She was determined to unlock the\n",
      "---------------\n",
      "Wrote generated sentence to generated-sentence-temp-0.txt.\n",
      "Tiempo: generate_sentence ejecutada en 3.2544 segundos\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "args.filepath = f'{args.option}-{args.epochs}-{args.lr}.pt'\n",
    "seed_everything(args.seed)\n",
    "\n",
    "prefix = \"Victor Frankenstein, a young scientist obsessed with uncovering the secrets of life, succeeds in animating a creature assembled from\"\n",
    "\n",
    "timed_generate_sentence(args, prefix, args.generated_sentence_low_temp_out, max_new_tokens=75, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11e384c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from stories42M.pt\n",
      "Temperature is 1.0\n",
      "Victor Frankenstein, a young scientist obsessed with uncovering the secrets of life, succeeds in animating a creature assembled from the unknown. One day, a three year old boy called Timmy and his parents were visiting his grandparents. Timmy was so excited to show them what he had been dreaming of.\n",
      "\"What did he have dream of,\" his dad asked. \n",
      "Timmy's dad smiled. He was happy to tell Timmy the story of\n",
      "---------------\n",
      "Wrote generated sentence to generated-sentence-temp-1.txt.\n",
      "Tiempo: generate_sentence ejecutada en 1.9764 segundos\n"
     ]
    }
   ],
   "source": [
    "timed_generate_sentence(args, prefix, args.generated_sentence_high_temp_out, max_new_tokens=75, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f50911",
   "metadata": {},
   "source": [
    "**Generación Mejorada al Implementar top_k y top_p al sampler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9daa90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from stories42M.pt\n",
      "Temperature is 0.7\n",
      "Victor Frankenstein, a young scientist obsessed with uncovering the secrets of life, succeeds in animating a creature assembled from the unknown. One day, a young girl called Lucy was walking in the woods. She was looking for something. Suddenly, Lucy saw the creature and ran away. Lucy was scared and ran home.\n",
      "The next day, Lucy was brave and faced the unknown creature. She was scared, but she kept running. Suddenly, the creature was caught\n",
      "---------------\n",
      "Wrote generated sentence to generated-sentence-temp-0.txt.\n",
      "Tiempo: generate_sentence ejecutada en 1.9861 segundos\n"
     ]
    }
   ],
   "source": [
    "args = Args()\n",
    "args.filepath = f'{args.option}-{args.epochs}-{args.lr}.pt'\n",
    "seed_everything(args.seed)\n",
    "\n",
    "prefix = \"Victor Frankenstein, a young scientist obsessed with uncovering the secrets of life, succeeds in animating a creature assembled from\"\n",
    "\n",
    "timed_generate_sentence(args, prefix, args.generated_sentence_low_temp_out, max_new_tokens=75, temperature=0.7, top_k=50, top_p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6e37b",
   "metadata": {},
   "source": [
    "## Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1388656",
   "metadata": {},
   "source": [
    "### SST Dataset\n",
    "**Comando Original**:\n",
    "python run_llama.py --option prompt --batch_size 10 --train data/sst-train.txt --dev data/sst-dev.txt --test data/sst-test.txt --label-names data/sst-label-mapping.json --dev_out sst-dev-prompting-output.txt --test_out sst-test-prompting-output.txt [--use_gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f53d4296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 8544 data from data/sst-train.txt\n",
      "load 1101 data from data/sst-dev.txt\n",
      "load 2210 data from data/sst-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 111/111 [00:02<00:00, 54.62it/s]\n",
      "eval: 100%|██████████| 221/221 [00:04<00:00, 53.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev acc :: 0.237\n",
      "test acc :: 0.250\n",
      "Tiempo: test_with_prompting ejecutada en 7.9520 segundos\n"
     ]
    }
   ],
   "source": [
    "args = Args(batch_size=10, train=\"data/sst-train.txt\", dev=\"data/sst-dev.txt\", test=\"data/sst-test.txt\", label_names=\"data/sst-label-mapping.json\", dev_out=\"sst-dev-prompting-output.txt\", test_out=\"sst-test-prompting-output.txt\")\n",
    "args.filepath = f'{args.option}-{args.epochs}-{args.lr}.pt'\n",
    "seed_everything(args.seed)\n",
    "\n",
    "timed_test_with_prompting(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f8f6a",
   "metadata": {},
   "source": [
    "### CFIMDB Dataset\n",
    "**Comando Original**: python run_llama.py --option prompt --batch_size 10 --train data/cfimdb-train.txt --dev data/cfimdb-dev.txt --test data/cfimdb-test.txt --label-names data/cfimdb-label-mapping.json --dev_out cfimdb-dev-prompting-output.txt --test_out cfimdb-test-prompting-output.txt [--use_gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a0f9411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 1707 data from data/cfimdb-train.txt\n",
      "load 245 data from data/cfimdb-dev.txt\n",
      "load 488 data from data/cfimdb-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 25/25 [00:02<00:00,  9.70it/s]\n",
      "eval: 100%|██████████| 49/49 [00:04<00:00, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev acc :: 0.490\n",
      "test acc :: 0.109\n",
      "Tiempo: test_with_prompting ejecutada en 9.3763 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(batch_size=10, train=\"data/cfimdb-train.txt\", dev=\"data/cfimdb-dev.txt\", test=\"data/cfimdb-test.txt\", \n",
    "            label_names=\"data/cfimdb-label-mapping.json\", dev_out=\"cfimdb-dev-prompting-output.txt\", \n",
    "            test_out=\"cfimdb-test-prompting-output.txt\")\n",
    "args.filepath = f'{args.option}-{args.epochs}-{args.lr}.pt'\n",
    "seed_everything(args.seed)\n",
    "timed_test_with_prompting(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc341e64",
   "metadata": {},
   "source": [
    "## Classification Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0c8ff",
   "metadata": {},
   "source": [
    "### SST Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0fc712",
   "metadata": {},
   "source": [
    "**Comando Original**: python run_llama.py --option finetune --epochs 5 --lr 2e-5 --batch_size 80 --train data/sst-train.txt --dev data/sst-dev.txt --test data/sst-test.txt --label-names data/sst-label-mapping.json --dev_out sst-dev-finetuning-output.txt --test_out sst-test-finetuning-output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75a02f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAIN---\n",
      "load 8544 data from data/sst-train.txt\n",
      "load 1101 data from data/sst-dev.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-0: 100%|██████████| 107/107 [00:31<00:00,  3.41it/s]\n",
      "eval: 100%|██████████| 107/107 [00:10<00:00,  9.80it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00, 10.51it/s]\n",
      " 20%|██        | 1/5 [00:45<03:00, 45.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 0: train loss :: 1.905, train acc :: 0.262, dev acc :: 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-1: 100%|██████████| 107/107 [00:31<00:00,  3.35it/s]\n",
      "eval: 100%|██████████| 107/107 [00:10<00:00,  9.76it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00, 10.37it/s]\n",
      " 40%|████      | 2/5 [01:30<02:15, 45.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 1: train loss :: 1.641, train acc :: 0.304, dev acc :: 0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-2: 100%|██████████| 107/107 [00:32<00:00,  3.32it/s]\n",
      "eval: 100%|██████████| 107/107 [00:11<00:00,  9.55it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00, 10.33it/s]\n",
      " 60%|██████    | 3/5 [02:16<01:31, 45.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 2: train loss :: 1.449, train acc :: 0.479, dev acc :: 0.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-3: 100%|██████████| 107/107 [00:32<00:00,  3.29it/s]\n",
      "eval: 100%|██████████| 107/107 [00:11<00:00,  9.49it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00, 10.38it/s]\n",
      " 80%|████████  | 4/5 [03:02<00:45, 45.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 3: train loss :: 1.225, train acc :: 0.553, dev acc :: 0.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-4: 100%|██████████| 107/107 [00:32<00:00,  3.30it/s]\n",
      "eval: 100%|██████████| 107/107 [00:11<00:00,  9.53it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00, 10.30it/s]\n",
      "100%|██████████| 5/5 [03:49<00:00, 45.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 4: train loss :: 0.975, train acc :: 0.761, dev acc :: 0.400\n",
      "Tiempo: train ejecutada en 231.0661 segundos\n",
      "---TEST---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from generate-5-2e-05.pt\n",
      "load 1101 data from data/sst-dev.txt\n",
      "load 2210 data from data/sst-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 14/14 [00:01<00:00,  9.71it/s]\n",
      "eval: 100%|██████████| 28/28 [00:02<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev acc :: 0.400\n",
      "test acc :: 0.408\n",
      "Tiempo: test ejecutada en 5.9013 segundos\n"
     ]
    }
   ],
   "source": [
    "args = Args(epochs=5, batch_size=80, lr=2e-5, train=\"data/sst-train.txt\", dev=\"data/sst-dev.txt\", test=\"data/sst-test.txt\", \n",
    "            label_names=\"data/sst-label-mapping.json\", dev_out=\"sst-dev-finetuning-output.txt\", \n",
    "            test_out=\"sst-test-finetuning-output.txt\")\n",
    "args.filepath = f'{args.option}-{args.epochs}-{args.lr}.pt'\n",
    "seed_everything(args.seed)\n",
    "print(\"---TRAIN---\")\n",
    "timed_train(args)\n",
    "\n",
    "print(\"---TEST---\")\n",
    "timed_test(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e92087",
   "metadata": {},
   "source": [
    "### CFIMDB DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080a2e5",
   "metadata": {},
   "source": [
    "**Comando Original**:\n",
    "python run_llama.py --option finetune --epochs 5 --lr 2e-5 --batch_size 10 --train data/cfimdb-train.txt --dev data/cfimdb-dev.txt --test data/cfimdb-test.txt --label-names data/cfimdb-label-mapping.json --dev_out cfimdb-dev-finetuning-output.txt --test_out cfimdb-test-finetuning-output.txt [--use_gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b63fdb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAIN---\n",
      "load 1707 data from data/cfimdb-train.txt\n",
      "load 245 data from data/cfimdb-dev.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-0: 100%|██████████| 171/171 [01:44<00:00,  1.63it/s]\n",
      "eval: 100%|██████████| 171/171 [00:38<00:00,  4.48it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  4.11it/s]\n",
      " 20%|██        | 1/5 [02:30<10:01, 150.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 0: train loss :: 0.992, train acc :: 0.501, dev acc :: 0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-1: 100%|██████████| 171/171 [01:43<00:00,  1.65it/s]\n",
      "eval: 100%|██████████| 171/171 [00:38<00:00,  4.46it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  4.06it/s]\n",
      " 40%|████      | 2/5 [04:59<07:28, 149.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 1: train loss :: 0.799, train acc :: 0.624, dev acc :: 0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-2: 100%|██████████| 171/171 [01:46<00:00,  1.61it/s]\n",
      "eval: 100%|██████████| 171/171 [00:38<00:00,  4.42it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  3.95it/s]\n",
      " 60%|██████    | 3/5 [07:30<05:00, 150.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train loss :: 0.761, train acc :: 0.544, dev acc :: 0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-3: 100%|██████████| 171/171 [01:43<00:00,  1.66it/s]\n",
      "eval: 100%|██████████| 171/171 [00:39<00:00,  4.30it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  4.09it/s]\n",
      " 80%|████████  | 4/5 [10:00<02:30, 150.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 3: train loss :: 0.703, train acc :: 0.793, dev acc :: 0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train-4: 100%|██████████| 171/171 [01:47<00:00,  1.59it/s]\n",
      "eval: 100%|██████████| 171/171 [00:39<00:00,  4.34it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  4.05it/s]\n",
      "100%|██████████| 5/5 [12:34<00:00, 150.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "epoch 4: train loss :: 0.402, train acc :: 0.896, dev acc :: 0.833\n",
      "Tiempo: train ejecutada en 755.9370 segundos\n",
      "---TEST---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from generate-5-2e-05.pt\n",
      "load 245 data from data/cfimdb-dev.txt\n",
      "load 488 data from data/cfimdb-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 25/25 [00:05<00:00,  4.66it/s]\n",
      "eval: 100%|██████████| 49/49 [00:08<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev acc :: 0.833\n",
      "test acc :: 0.590\n",
      "Tiempo: test ejecutada en 15.5409 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(batch_size=10, epochs=5, lr=2e-5, train=\"data/cfimdb-train.txt\", dev=\"data/cfimdb-dev.txt\", test=\"data/cfimdb-test.txt\", \n",
    "            label_names=\"data/cfimdb-label-mapping.json\", dev_out=\"cfimdb-dev-finetuning-output.txt\", \n",
    "            test_out=\"cfimdb-test-finetuning-output.txt\")\n",
    "args.filepath = f'{args.option}-{args.epochs}-{args.lr}.pt'\n",
    "seed_everything(args.seed)\n",
    "\n",
    "print(\"---TRAIN---\")\n",
    "timed_train(args)\n",
    "\n",
    "print(\"---TEST---\")\n",
    "timed_test(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a36dfd",
   "metadata": {},
   "source": [
    "## LoRA Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828070dd",
   "metadata": {},
   "source": [
    "### SST DataSet\n",
    "**Comando Original**:\n",
    "python run_llama.py --option lora --epochs 5 --lr 2e-5 --batch_size 80 --train data/sst-train.txt --dev data/sst-dev.txt --test data/sst-test.txt --label-names data/sst-label-mapping.json --dev_out sst-dev-lora-output.txt --test_out sst-test-lora-output.txt --lora_rank 4 --lora_alpha 1.0 [--use_gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78267413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAIN---\n",
      "load 8544 data from data/sst-train.txt\n",
      "load 1101 data from data/sst-dev.txt\n",
      "Applying LoRA with rank=4, alpha=1.0\n",
      "Applied LoRA to layers.0.attention.compute_query\n",
      "Applied LoRA to layers.0.attention.compute_key\n",
      "Applied LoRA to layers.0.attention.compute_value\n",
      "Applied LoRA to layers.0.attention.compute_output\n",
      "Applied LoRA to layers.1.attention.compute_query\n",
      "Applied LoRA to layers.1.attention.compute_key\n",
      "Applied LoRA to layers.1.attention.compute_value\n",
      "Applied LoRA to layers.1.attention.compute_output\n",
      "Applied LoRA to layers.2.attention.compute_query\n",
      "Applied LoRA to layers.2.attention.compute_key\n",
      "Applied LoRA to layers.2.attention.compute_value\n",
      "Applied LoRA to layers.2.attention.compute_output\n",
      "Applied LoRA to layers.3.attention.compute_query\n",
      "Applied LoRA to layers.3.attention.compute_key\n",
      "Applied LoRA to layers.3.attention.compute_value\n",
      "Applied LoRA to layers.3.attention.compute_output\n",
      "Applied LoRA to layers.4.attention.compute_query\n",
      "Applied LoRA to layers.4.attention.compute_key\n",
      "Applied LoRA to layers.4.attention.compute_value\n",
      "Applied LoRA to layers.4.attention.compute_output\n",
      "Applied LoRA to layers.5.attention.compute_query\n",
      "Applied LoRA to layers.5.attention.compute_key\n",
      "Applied LoRA to layers.5.attention.compute_value\n",
      "Applied LoRA to layers.5.attention.compute_output\n",
      "Applied LoRA to layers.6.attention.compute_query\n",
      "Applied LoRA to layers.6.attention.compute_key\n",
      "Applied LoRA to layers.6.attention.compute_value\n",
      "Applied LoRA to layers.6.attention.compute_output\n",
      "Applied LoRA to layers.7.attention.compute_query\n",
      "Applied LoRA to layers.7.attention.compute_key\n",
      "Applied LoRA to layers.7.attention.compute_value\n",
      "Applied LoRA to layers.7.attention.compute_output\n",
      "Training 66 parameter groups (LoRA + classifier)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-0: 100%|██████████| 107/107 [00:32<00:00,  3.33it/s]\n",
      "eval: 100%|██████████| 107/107 [00:12<00:00,  8.30it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA weights back into original model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:47<03:10, 47.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "Saved merged model to generate-5-2e-05.pt\n",
      "LoRA epoch 0: train loss :: 3.830, train acc :: 0.235, dev acc :: 0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-1: 100%|██████████| 107/107 [00:32<00:00,  3.29it/s]\n",
      "eval: 100%|██████████| 107/107 [00:12<00:00,  8.34it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA weights back into original model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:35<02:23, 47.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "Saved merged model to generate-5-2e-05.pt\n",
      "LoRA epoch 1: train loss :: 2.531, train acc :: 0.260, dev acc :: 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-2: 100%|██████████| 107/107 [00:32<00:00,  3.28it/s]\n",
      "eval: 100%|██████████| 107/107 [00:13<00:00,  8.22it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA weights back into original model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:23<01:35, 47.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "Saved merged model to generate-5-2e-05.pt\n",
      "LoRA epoch 2: train loss :: 2.442, train acc :: 0.263, dev acc :: 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-3: 100%|██████████| 107/107 [00:32<00:00,  3.27it/s]\n",
      "eval: 100%|██████████| 107/107 [00:12<00:00,  8.25it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00,  8.71it/s]\n",
      " 80%|████████  | 4/5 [03:11<00:47, 47.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA epoch 3: train loss :: 2.382, train acc :: 0.261, dev acc :: 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-4: 100%|██████████| 107/107 [00:32<00:00,  3.29it/s]\n",
      "eval: 100%|██████████| 107/107 [00:13<00:00,  8.22it/s]\n",
      "eval: 100%|██████████| 14/14 [00:01<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA weights back into original model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:59<00:00, 47.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "Saved merged model to generate-5-2e-05.pt\n",
      "LoRA epoch 4: train loss :: 2.312, train acc :: 0.264, dev acc :: 0.268\n",
      "Tiempo: train_lora ejecutada en 241.3057 segundos\n",
      "---TEST---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from generate-5-2e-05.pt\n",
      "load 1101 data from data/sst-dev.txt\n",
      "load 2210 data from data/sst-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 14/14 [00:01<00:00,  9.85it/s]\n",
      "eval: 100%|██████████| 28/28 [00:02<00:00,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev acc :: 0.268\n",
      "test acc :: 0.256\n",
      "Tiempo: test ejecutada en 5.7941 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(epochs=5, batch_size=80, lr=2e-5, train=\"data/sst-train.txt\", dev=\"data/sst-dev.txt\", test=\"data/sst-test.txt\", \n",
    "            label_names=\"data/sst-label-mapping.json\", dev_out=\"sst-dev-lora-output.txt\", \n",
    "            test_out=\"sst-test-lora-output.txt\", lora_rank=4, lora_alpha=1.0)\n",
    "args.filepath = f'{args.option}-{args.epochs}-{args.lr}.pt'\n",
    "seed_everything(args.seed)\n",
    "\n",
    "print(\"---TRAIN---\")\n",
    "timed_train_lora(args)\n",
    "\n",
    "print(\"---TEST---\")\n",
    "timed_test(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10972af9",
   "metadata": {},
   "source": [
    "### CFIMDB DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91e655",
   "metadata": {},
   "source": [
    "**Comando Original**: python run_llama.py --option lora --epochs 5 --lr 2e-5 --batch_size 10 --train data/cfimdb-train.txt --dev data/cfimdb-dev.txt --test data/cfimdb-test.txt --label-names data/cfimdb-label-mapping.json --dev_out cfimdb-dev-lora-output.txt --test_out cfimdb-test-lora-output.txt --lora_rank 4 --lora_alpha 1.0 [--use_gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a988b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TRAIN---\n",
      "load 1707 data from data/cfimdb-train.txt\n",
      "load 245 data from data/cfimdb-dev.txt\n",
      "Applying LoRA with rank=4, alpha=1.0\n",
      "Applied LoRA to layers.0.attention.compute_query\n",
      "Applied LoRA to layers.0.attention.compute_key\n",
      "Applied LoRA to layers.0.attention.compute_value\n",
      "Applied LoRA to layers.0.attention.compute_output\n",
      "Applied LoRA to layers.1.attention.compute_query\n",
      "Applied LoRA to layers.1.attention.compute_key\n",
      "Applied LoRA to layers.1.attention.compute_value\n",
      "Applied LoRA to layers.1.attention.compute_output\n",
      "Applied LoRA to layers.2.attention.compute_query\n",
      "Applied LoRA to layers.2.attention.compute_key\n",
      "Applied LoRA to layers.2.attention.compute_value\n",
      "Applied LoRA to layers.2.attention.compute_output\n",
      "Applied LoRA to layers.3.attention.compute_query\n",
      "Applied LoRA to layers.3.attention.compute_key\n",
      "Applied LoRA to layers.3.attention.compute_value\n",
      "Applied LoRA to layers.3.attention.compute_output\n",
      "Applied LoRA to layers.4.attention.compute_query\n",
      "Applied LoRA to layers.4.attention.compute_key\n",
      "Applied LoRA to layers.4.attention.compute_value\n",
      "Applied LoRA to layers.4.attention.compute_output\n",
      "Applied LoRA to layers.5.attention.compute_query\n",
      "Applied LoRA to layers.5.attention.compute_key\n",
      "Applied LoRA to layers.5.attention.compute_value\n",
      "Applied LoRA to layers.5.attention.compute_output\n",
      "Applied LoRA to layers.6.attention.compute_query\n",
      "Applied LoRA to layers.6.attention.compute_key\n",
      "Applied LoRA to layers.6.attention.compute_value\n",
      "Applied LoRA to layers.6.attention.compute_output\n",
      "Applied LoRA to layers.7.attention.compute_query\n",
      "Applied LoRA to layers.7.attention.compute_key\n",
      "Applied LoRA to layers.7.attention.compute_value\n",
      "Applied LoRA to layers.7.attention.compute_output\n",
      "Training 66 parameter groups (LoRA + classifier)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-0: 100%|██████████| 171/171 [01:43<00:00,  1.66it/s]\n",
      "eval: 100%|██████████| 171/171 [00:38<00:00,  4.45it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging LoRA weights back into original model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:28<09:53, 148.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save the model to generate-5-2e-05.pt\n",
      "Saved merged model to generate-5-2e-05.pt\n",
      "LoRA epoch 0: train loss :: 1.195, train acc :: 0.502, dev acc :: 0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-1: 100%|██████████| 171/171 [01:40<00:00,  1.70it/s]\n",
      "eval: 100%|██████████| 171/171 [00:37<00:00,  4.56it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  3.89it/s]\n",
      " 40%|████      | 2/5 [04:52<07:18, 146.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA epoch 1: train loss :: 1.113, train acc :: 0.508, dev acc :: 0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-2: 100%|██████████| 171/171 [01:40<00:00,  1.70it/s]\n",
      "eval: 100%|██████████| 171/171 [00:38<00:00,  4.41it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  3.88it/s]\n",
      " 60%|██████    | 3/5 [07:18<04:51, 145.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA epoch 2: train loss :: 1.091, train acc :: 0.511, dev acc :: 0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-3: 100%|██████████| 171/171 [01:37<00:00,  1.76it/s]\n",
      "eval: 100%|██████████| 171/171 [00:37<00:00,  4.54it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  3.88it/s]\n",
      " 80%|████████  | 4/5 [09:40<02:24, 144.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA epoch 3: train loss :: 1.104, train acc :: 0.523, dev acc :: 0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lora-train-4: 100%|██████████| 171/171 [01:31<00:00,  1.86it/s]\n",
      "eval: 100%|██████████| 171/171 [00:37<00:00,  4.52it/s]\n",
      "eval: 100%|██████████| 25/25 [00:06<00:00,  3.88it/s]\n",
      "100%|██████████| 5/5 [11:56<00:00, 143.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA epoch 4: train loss :: 1.059, train acc :: 0.511, dev acc :: 0.490\n",
      "Tiempo: train_lora ejecutada en 718.2622 segundos\n",
      "---TEST---\n",
      "load model from generate-5-2e-05.pt\n",
      "load 245 data from data/cfimdb-dev.txt\n",
      "load 488 data from data/cfimdb-test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 25/25 [00:05<00:00,  4.78it/s]\n",
      "eval: 100%|██████████| 49/49 [00:08<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev acc :: 0.518\n",
      "test acc :: 0.424\n",
      "Tiempo: test ejecutada en 15.3864 segundos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = Args(batch_size=10, epochs=5, lr=2e-5, train=\"data/cfimdb-train.txt\", dev=\"data/cfimdb-dev.txt\", test=\"data/cfimdb-test.txt\", \n",
    "            label_names=\"data/cfimdb-label-mapping.json\", dev_out=\"cfimdb-dev-lora-output.txt\", \n",
    "            test_out=\"cfimdb-test-lora-output.txt\", lora_rank=4, lora_alpha=1.0)\n",
    "args.filepath = f'{args.option}-{args.epochs}-{args.lr}.pt'\n",
    "seed_everything(args.seed)\n",
    "print(\"---TRAIN---\")\n",
    "timed_train_lora(args)\n",
    "print(\"---TEST---\")\n",
    "timed_test(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
